# LANE-DETECTION-MASTER-2
Use tensorflow to implement a Deep Neural Network for real time lane detection mainly based on the IEEE IV conference paper "Towards End-to-End Lane Detection: an Instance Segmentation Approach".You can refer to their paper for details https://arxiv.org/abs/1802.05591. This model consists of a encoder-decoder stage, binary semantic segmentation stage and instance semantic segmentation using discriminative loss function for real time lane detection task.  The main network architecture is as follows:                   Train your own model : Data Preparation Firstly you need to organize your training data refer to the data/training_data_example folder structure. And you need to generate a train.txt and a val.txt to record the data used for training the model.  The training samples are consist of three components. A binary segmentation label file and a instance segmentation label file and the original image. The binary segmentation use 255 to represent the lane field and 0 for the rest. The instance use different pixel value to represent different lane field and 0 for the rest.  All your training image will be scaled into the same scale according to the config file.  Use the script here to generate the tensorflow records file  python tools/make_tusimple_tfrecords.py  Train model In my experiment the training epochs are 80010, batch size is 4, initialized learning rate is 0.001 and use polynomial decay with power 0.9. About training parameters you can check the global_configuration/config.py for details. You can switch --net argument to change the base encoder stage. If you choose --net vgg then the vgg16 will be used as the base encoder stage and a pretrained parameters will be loaded. And you can modified the training script to load your own pretrained parameters or you can implement your own base encoder stage. You may call the following script to train your own model  python tools/train_lanenet_tusimple.py  You may monitor the training process using tensorboard tools  During my experiment the Total loss drops as follows:        Recently updates 2018.11.10 :       Adjust some basic cnn op according to the new tensorflow api. Use the traditional SGD optimizer to optimize the whole model instead of the origin Adam optimizer used in the origin paper. I have found that the SGD optimizer will lead to more stable training process and will not easily stuck into nan loss which may often happen when using the origin code.
